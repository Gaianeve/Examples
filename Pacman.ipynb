{"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Burocracy\n1. checking GPU\n2. install dependencies\n3. import libraries","metadata":{"id":"NNmwLx0-UAJa"}},{"cell_type":"code","source":"##1. setting gpu\nimport tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227},"id":"9MhA4PKYUFce","outputId":"887c4b26-1ed0-4a91-d655-31fbd58c2f41","execution":{"iopub.status.busy":"2023-09-07T13:03:43.252428Z","iopub.execute_input":"2023-09-07T13:03:43.252779Z","iopub.status.idle":"2023-09-07T13:03:54.736384Z","shell.execute_reply.started":"2023-09-07T13:03:43.252745Z","shell.execute_reply":"2023-09-07T13:03:54.735233Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Found GPU at: /device:GPU:0\n","output_type":"stream"}]},{"cell_type":"code","source":"## 2. installation: some of these are requiered for pacman environment\n\n!pip install gym pyvirtualdisplay > /dev/null 2>&1\n!apt-get update > /dev/null 2>&1\n!apt-get install cmake > /dev/null 2>&1\n!pip install --upgrade setuptools 2>&1\n!pip install ez_setup > /dev/null 2>&1\n!pip install gym[atari] > /dev/null 2>&1\n!apt-get install -y xvfb python-opengl ffmpeg > /dev/null\n\n!apt-get install x11-utils > /dev/null 2>&1\n!pip install pyglet > /dev/null 2>&1","metadata":{"id":"M3MQIZX-UF68","execution":{"iopub.status.busy":"2023-09-07T13:03:54.738050Z","iopub.execute_input":"2023-09-07T13:03:54.738636Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (68.0.0)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fcf0f16a7a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/setuptools/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fcf0f16aad0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/setuptools/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fcf0f16ac80>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/setuptools/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fcf0f16ae30>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/setuptools/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fcf0f16afe0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/setuptools/\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#installing gym things for atari. Guess u need this version here\n!pip install -U gym>=0.21.0\n!pip install -U gym[atari,accept-rom-license]","metadata":{"id":"zq2z9pJkgmuc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gym\nimport numpy as np\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt\n#display plot in a notebook\n%matplotlib inline\nimport random\nfrom collections import deque, Counter\nfrom datetime import datetime\n\n# ML libraries\nimport tensorflow as tf\nfimport matplotlib.pyplot as plt\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Flatten\n\n#graphic render of the environment\nfrom IPython import display as ipythondisplay","metadata":{"id":"T-XMgovrUJW5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pacman environment\nthe goal is to teach the computer to play Pacman. Let's look at the environment","metadata":{"id":"6UgqWZzAXngb"}},{"cell_type":"code","source":"#needed but don't know why, guess it's something with ale. Still, this way it works\nfrom ale_py import ALEInterface\nale = ALEInterface()\n\nfrom ale_py.roms import MsPacman\nale.loadROM(MsPacman)","metadata":{"colab":{"background_save":true},"id":"OfuAVtwkduiq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env = gym.make('ALE/MsPacman-v5', render_mode=\"rgb_array\")\n## useful if u want to look at the environment\n#prev_screen = env.render()\n#plt.imshow(prev_screen)\n#ipythondisplay.clear_output(wait=True)","metadata":{"id":"Dn6lPUHVXwTR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define functions i need","metadata":{}},{"cell_type":"markdown","source":"## Process image\nNow we define a function called preprocess_observation for preprocessing our input game screen. We reduce the image size and convert the image into greyscale.\n\n","metadata":{"id":"Gwy6xqRl1w-1"}},{"cell_type":"code","source":"#functions for preprocessing\n\ndef cropping(start_obs):\n  # Cropping image: to choose the value, u should look at the image\n  img = start_obs[1:176:2,::2]\n  #show modified image\n  '''\n  print('Cropping image')\n  plt.imshow(img)\n  ipythondisplay.clear_output(wait=True)\n  '''\n  return img\n\ndef to_greyscale(img):\n  # Convert the image to greyscale\n  img = img.mean(axis=2)\n  #show modified image\n  '''\n  print('Turn to greyscale')\n  plt.imshow(img)\n  ipythondisplay.clear_output(wait=True)\n  '''\n  return img\n\ndef improve_contrast(img):\n  # Improve image contrast\n  color = np.array([210, 164, 74]).mean()\n  img[img==color] = 0\n  #show modified image\n  '''\n  print('More contrast')\n  plt.imshow(img)\n  ipythondisplay.clear_output(wait=True)\n  '''\n  return img\n\ndef normalize(img):\n  #Normalize the image from -1 to +1\n  img = (img - 128) / 128 - 1\n  #show modified image\n  '''\n  print('Normalize')\n  plt.imshow(img)\n  ipythondisplay.clear_output(wait=True)\n  '''\n  return img","metadata":{"id":"t9S96lKofWK0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**REMEMBER: gotta pass to preprocess_observation, observation[0], and not all the observation matrix**","metadata":{"id":"2TpE0w81pjAo"}},{"cell_type":"code","source":"def preprocess_observation(obs):\n  #1. crop\n  image = cropping(obs)\n  #2. greyscale\n  image = to_greyscale(image)\n  #3. contrast\n  image = improve_contrast(image)\n  #4. normalize in [-1;+1]\n  image = normalize(image)\n  # 5. reshape image\n  image = image.reshape(88,80,1)\n  return image","metadata":{"id":"JefjATHMUWVe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building Q network\nQ network is the predicting network, which is used to predict the weights. The input is the game state X. The output has the dimension of the action space, so it's one place for one action.\n\nThe Q network below has three convolutional layers with SAME padding, followed by a fully connected layer.","metadata":{"id":"SHobCE0sqJCw"}},{"cell_type":"code","source":"def q_network(screen_shape, learning_rate):\n    #input\n    start_state = Input(shape = screen_shape)\n\n    #initialize weights\n    w_start = tf.keras.initializers.VarianceScaling()\n\n    #layers\n    x = Conv2D(32, kernel_size = (8,8), strides = 4, padding = 'SAME',\\\n               kernel_initializer =w_start, name = 'conv_1' )(start_state) #first layer\n    x = Conv2D(64, kernel_size = (4,4), strides = 2, padding = 'SAME',\\\n               kernel_initializer =w_start, name = 'conv_2' )(x) #second layer\n    x = Conv2D(64, kernel_size = (3,3), strides = 1, padding = 'SAME',\\\n               kernel_initializer =w_start, name = 'conv_3' )(x) #thrid layer\n    flatten = Flatten(name='flatten')(x) #flatten output\n    fully_connected = Dense(128, kernel_initializer =w_start, name = 'fc')(flatten)  #fully connected layer\n    out_layer = Dense(18,kernel_initializer =w_start, name = 'output')(fully_connected) #output\n\n    model = Model(start_state, out_layer)\n\n    #summarize and compile model\n    model.summary()\n    model.compile(optimizer= Adam(lr = learning_rate), loss = \"mse\")\n\n    return model","metadata":{"id":"KT22Ggi7oa04"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE**: the name 'SAME' padding just came from the property that when stride equals 1, output spatial shape is the same as input spatial shape. In general case, the definition of 'SAME' means to apply the padding in a tensorflow way such that:\n\n*For each spatial dimension i:\noutput_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i])*.\n\n\nBasically, padding = 'SAME' concers the dimention of input and output.","metadata":{"id":"S3119sbZs-MO"}},{"cell_type":"markdown","source":"## Epsilon greedy policy\nThe value of epsilon decay over time","metadata":{}},{"cell_type":"code","source":"def epsilon_greedy(action, step,eps_min,eps_max,eps_decay_steps,n_outputs):\n    tmp = eps_max - (eps_max-eps_min) * step/eps_decay_steps\n    epsilon = max(eps_min,tmp)\n    rand_tmp = np.random.rand()\n    if rand_tmp < epsilon:\n        return np.random.randint(n_outputs) #returna un numero tra 0 e n output\n    else:\n        return action","metadata":{"id":"p8pqBn5etbLc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Replay buffer","metadata":{}},{"cell_type":"code","source":"def sample_memories(batch_size, exp_buffer):\n    perm_batch = np.random.permutation(len(exp_buffer))[:batch_size]\n    # permuta in modo randomico np.arange(x), e poi prendiamo solo la prima botta di batch\n    print('perm_batch')\n    print(perm_batch)\n    mem = np.array(exp_buffer)[perm_batch]\n    print('mem')\n    print(mem)\n    return [mem[:,0], mem[:,1], mem[:,2], mem[:,3], mem[:,4]]\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameters\nParameters whose value is used to control learning *process*","metadata":{}},{"cell_type":"code","source":"n_action = env.action_space.n\nn_episode = 800\n\n# nn variables\nbatch_size = 48\ninput_shape = (88,80,1)\nlearning_rate_alpha = 0.001\n\n#epsilon greedy policy variables\nmin_eps = 0.05\nmax_eps = 1\ndecay_steps_epsilon = 500000 \n\n# training variables\ndiscount_factor = 0.97\nglobal_step = 0\nsteps_train = 4\nstart_steps = 2000\ncopy_steps = 100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build Q network, that takes input X, initial screen state and generates Q values for all the actions\n#in the state\nQ_network = q_network(input_shape, learning_rate_alpha)\ntarget_Q_network = q_network(input_shape, learning_rate_alpha)","metadata":{},"execution_count":null,"outputs":[]}]}